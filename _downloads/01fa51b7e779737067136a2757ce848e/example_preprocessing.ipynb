{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nExample demonstrating preprocessing and imputation tools for DrillholeDatabase.\n\nThis example shows how to:\n1. Validate numerical columns in assay data\n2. Filter rows based on NaN thresholds\n3. Chain preprocessing operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nfrom loopresources.drillhole.drillhole_database import DrillholeDatabase\nfrom loopresources.drillhole.dhconfig import DhConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Sample Data\nCreate synthetic drillhole data with some quality issues\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\nprint(\"Preprocessing and Imputation Tools - Example\")\nprint(\"=\" * 70)\n\n# Collar data\ncollar = pd.DataFrame(\n    {\n        DhConfig.holeid: [\"DH001\", \"DH002\", \"DH003\"],\n        DhConfig.x: [100.0, 200.0, 300.0],\n        DhConfig.y: [1000.0, 2000.0, 3000.0],\n        DhConfig.z: [50.0, 60.0, 70.0],\n        DhConfig.total_depth: [100.0, 150.0, 200.0],\n    }\n)\n\n# Survey data\nsurvey = pd.DataFrame(\n    {\n        DhConfig.holeid: [\"DH001\", \"DH001\", \"DH002\", \"DH002\", \"DH003\"],\n        DhConfig.depth: [0.0, 50.0, 0.0, 75.0, 0.0],\n        DhConfig.azimuth: [0.0, 0.0, 45.0, 45.0, 90.0],\n        DhConfig.dip: [90.0, 90.0, 80.0, 80.0, 85.0],\n    }\n)\n\n# Assay data with quality issues:\n# - Mixed data types (strings that should be numbers)\n# - Negative values (which may be data errors)\n# - Zero values (which may indicate below detection limit)\n# - Missing values (NaN)\nassay = pd.DataFrame(\n    {\n        DhConfig.holeid: [\"DH001\", \"DH001\", \"DH001\", \"DH002\", \"DH002\", \"DH003\", \"DH003\"],\n        DhConfig.depth: [10.0, 25.0, 40.0, 50.0, 80.0, 100.0, 150.0],\n        \"CU_PPM\": [\n            500.0,\n            \"invalid\",\n            -100.0,\n            0.0,\n            1200.0,\n            800.0,\n            650.0,\n        ],  # Mixed types, negative, zero\n        \"AU_PPM\": [0.5, 1.2, 0.8, \"N/A\", 1.5, -0.1, 0.9],  # String and negative\n        \"AG_PPM\": [10.0, 20.0, np.nan, np.nan, 15.0, 25.0, np.nan],  # Missing values\n        \"PB_PPM\": [5.0, np.nan, np.nan, np.nan, 8.0, 12.0, 10.0],  # Sparse data\n    }\n)\n\nprint(\"\\nOriginal Assay Data:\")\nprint(assay.to_string(index=False))\nprint(f\"\\nTotal records: {len(assay)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initialize Database\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "db = DrillholeDatabase(collar, survey)\ndb.add_point_table(\"assay\", assay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 1: Validate Numerical Columns\nClean the data by:\n- Converting strings to numbers (invalid values become NaN)\n- Replacing negative and zero values with NaN (allow_negative=False)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"Step 1: Validate Numerical Columns\")\nprint(\"=\" * 70)\n\ndb.validate_numerical_columns(\n    \"assay\",\n    columns=[\"CU_PPM\", \"AU_PPM\", \"AG_PPM\", \"PB_PPM\"],\n    allow_negative=False,  # Replace values <= 0 with NaN\n)\n\nprint(\"\\nAfter validation (strings and non-positive values replaced with NaN):\")\nprint(db.points[\"assay\"].to_string(index=False))\n\n# Count NaN values per column\nnan_counts = db.points[\"assay\"][[\"CU_PPM\", \"AU_PPM\", \"AG_PPM\", \"PB_PPM\"]].isna().sum()\nprint(\"\\nNaN count per column:\")\nprint(nan_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2: Filter by NaN Threshold\nRemove records where too many assay values are missing\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"Step 2: Filter by NaN Threshold\")\nprint(\"=\" * 70)\n\n# Keep only records where at least 75% of assay columns have valid values\nfiltered_db = db.filter_by_nan_threshold(\n    \"assay\",\n    columns=[\"CU_PPM\", \"AU_PPM\", \"AG_PPM\", \"PB_PPM\"],\n    threshold=0.75,  # At least 3 out of 4 columns must have valid data\n)\n\nprint(\"\\nAfter filtering (kept records with \u226575% valid values):\")\nprint(filtered_db.points[\"assay\"].to_string(index=False))\nprint(f\"\\nRecords remaining: {len(filtered_db.points['assay'])} / {len(assay)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Combined Workflow with Chaining\nDemonstrate chaining preprocessing with spatial filtering\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"Step 3: Combined Workflow with Chaining\")\nprint(\"=\" * 70)\n\n# Reset database\ndb = DrillholeDatabase(collar, survey)\ndb.add_point_table(\"assay\", assay.copy())\n\n# Chain operations:\n# 1. Validate numerical columns\n# 2. Filter spatially by holes\n# 3. Filter by NaN threshold\nresult_db = (\n    db.validate_numerical_columns(\"assay\", [\"CU_PPM\", \"AU_PPM\", \"AG_PPM\"], allow_negative=False)\n    .filter(holes=[\"DH001\", \"DH002\"])  # Only keep specific holes\n    .filter_by_nan_threshold(\"assay\", [\"CU_PPM\", \"AU_PPM\", \"AG_PPM\"], threshold=0.67)\n)\n\nprint(\"\\nAfter chained operations:\")\nprint(\"  1. Validated numerical columns\")\nprint(\"  2. Filtered to holes: DH001, DH002\")\nprint(\"  3. Filtered to records with \u226567% valid values\")\nprint(f\"\\nHoles remaining: {result_db.list_holes()}\")\nprint(f\"Records remaining: {len(result_db.points['assay'])} / {len(assay)}\")\nprint(\"\\nFinal assay data:\")\nprint(\n    result_db.points[\"assay\"][[\"HOLEID\", \"DEPTH\", \"CU_PPM\", \"AU_PPM\", \"AG_PPM\"]].to_string(\n        index=False\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary Statistics\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"Summary\")\nprint(\"=\" * 70)\n\nprint(f\"\\nOriginal data: {len(assay)} records across {len(collar)} holes\")\nprint(\n    f\"After preprocessing: {len(result_db.points['assay'])} records across {len(result_db.list_holes())} holes\"\n)\nprint(f\"Data retention: {len(result_db.points['assay']) / len(assay) * 100:.1f}%\")\n\nprint(\"\\nPreprocessing workflow successfully completed!\")\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}